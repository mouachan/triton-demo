# ğŸŒ¸ Triton Demo - Classification Iris

Ce projet dÃ©montre l'utilisation de NVIDIA Triton Inference Server pour dÃ©ployer et servir un modÃ¨le de classification Iris dans un environnement OpenShift AI.

## ğŸ“‹ PrÃ©requis

- OpenShift AI (RHODS) 2.22+
- ArgoCD configurÃ©
- Model Registry opÃ©rationnel
- MinIO/S3 accessible
- MySQL pour le Model Registry

## ğŸš€ DÃ©ploiement

### 1. DÃ©ploiement via GitOps

Le projet est configurÃ© pour Ãªtre dÃ©ployÃ© automatiquement via ArgoCD :

```bash
# VÃ©rifier que ArgoCD est synchronisÃ©
oc get applications -n openshift-gitops

# Forcer la synchronisation si nÃ©cessaire
oc patch application openshift-ai-complete -n openshift-gitops --type='merge' -p='{"spec":{"syncPolicy":{"automated":{"prune":true,"selfHeal":true}}}}'
```

### 2. Composants dÃ©ployÃ©s

- **MySQL Database** : `mysql.db-ai.svc.cluster.local:3306`
- **Model Registry** : `modelregistry` dans le namespace `rhoai-model-registries`
- **MinIO Storage** : `minio.db-ai.svc.cluster.local:9000`
- **Jupyter Workbench** : `triton-workbench` dans le namespace `triton-demo`
- **Triton Inference Server** : Pour servir les modÃ¨les

## ğŸ“Š Utilisation du Notebook

### 1. AccÃ¨s au Workbench

1. Connectez-vous Ã  OpenShift AI Dashboard
2. Allez dans le projet `triton-demo`
3. Lancez le workbench `triton-workbench`
4. Ouvrez le notebook `demos/triton-example/notebooks/iris_classification_notebook.ipynb`

### 2. Configuration automatique

Le workbench est configurÃ© avec :
- **Image** : `s2i-generic-data-science-notebook:2025.1`
- **Variables d'environnement** :
  - `MODEL_REGISTRY_URL` : URL du Model Registry
  - `AWS_S3_ENDPOINT` : Endpoint MinIO
  - `AWS_S3_BUCKET` : Bucket pour les modÃ¨les
  - `AWS_ACCESS_KEY_ID` / `AWS_SECRET_ACCESS_KEY` : Credentials S3

### 3. Test local

Vous pouvez tester le notebook localement :

```bash
cd demos/triton-example
python3 test_notebook.py
```

## ğŸ”§ Configuration

### Variables d'environnement

Le workbench utilise les variables suivantes :

```yaml
# Model Registry
MODEL_REGISTRY_URL: "https://modelregistry-rest.apps.cluster-v2mx6.v2mx6.sandbox1062.opentlc.com"
MODEL_REGISTRY_DATABASE_URL: "mysql://mlmduser:TheBlurstOfTimes@mysql.db-ai.svc.cluster.local:3306/model_registry"

# S3/MinIO
AWS_ACCESS_KEY_ID: "accesskey"
AWS_SECRET_ACCESS_KEY: "secretkey"
AWS_S3_ENDPOINT: "minio.db-ai.svc.cluster.local:9000"
AWS_S3_BUCKET: "model-registry"
AWS_S3_FORCE_PATH_STYLE: "true"
```

### Secrets

Le workbench utilise le secret `triton-demo-s3-connection` pour les credentials S3.

## ğŸ“ Structure du projet

```
demos/triton-example/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ iris_classification_notebook.ipynb  # Notebook principal
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ model_registry.py                   # Script pour Model Registry
â”‚   â”œâ”€â”€ model_training.py                   # Script d'entraÃ®nement
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                                 # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ data/                                   # DonnÃ©es
â”œâ”€â”€ test_notebook.py                        # Script de test local
â””â”€â”€ README.md                               # Ce fichier
```

## ğŸ¯ FonctionnalitÃ©s

### 1. EntraÃ®nement du modÃ¨le
- Chargement du dataset Iris
- EntraÃ®nement Random Forest
- Ã‰valuation des performances
- Sauvegarde du modÃ¨le

### 2. Conversion ONNX
- Conversion du modÃ¨le scikit-learn vers ONNX
- Validation du modÃ¨le ONNX
- Test d'infÃ©rence

### 3. Model Registry
- Enregistrement du modÃ¨le
- Upload vers S3/MinIO
- MÃ©tadonnÃ©es complÃ¨tes

### 4. Triton Inference
- DÃ©ploiement sur Triton
- Test d'infÃ©rence via API REST
- Monitoring des performances

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

1. **Workbench ne dÃ©marre pas**
   - VÃ©rifiez les ressources CPU/Memory
   - VÃ©rifiez l'image Docker
   - VÃ©rifiez les secrets S3

2. **Erreur de connexion S3**
   - VÃ©rifiez les credentials dans le secret
   - VÃ©rifiez l'endpoint MinIO
   - VÃ©rifiez la connectivitÃ© rÃ©seau

3. **Erreur Model Registry**
   - VÃ©rifiez l'URL du Model Registry
   - VÃ©rifiez la base de donnÃ©es MySQL
   - VÃ©rifiez les permissions

### Logs utiles

```bash
# Logs du workbench
oc logs -f deployment/triton-workbench -n triton-demo

# Logs du Model Registry
oc logs -f deployment/modelregistry -n rhoai-model-registries

# Logs MySQL
oc logs -f deployment/mysql -n db-ai
```

## ğŸ“ˆ Monitoring

### MÃ©triques importantes

- **Accuracy du modÃ¨le** : > 0.90
- **Latence d'infÃ©rence** : < 100ms
- **DisponibilitÃ©** : > 99.9%

### Dashboards

- **OpenShift AI Dashboard** : Vue d'ensemble
- **ArgoCD** : Ã‰tat du dÃ©ploiement GitOps
- **Grafana** : MÃ©triques dÃ©taillÃ©es

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez une branche feature
3. Committez vos changements
4. Poussez vers la branche
5. CrÃ©ez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ”— Liens utiles

- [OpenShift AI Documentation](https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed)
- [NVIDIA Triton Documentation](https://github.com/triton-inference-server/server)
- [Model Registry Documentation](https://model-registry.readthedocs.io/)
- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/)
