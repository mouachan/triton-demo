import os
import json
import pickle
import numpy as np
from pathlib import Path
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

def try_install_onnx():
    """Tentative d'installation ONNX sans forcer"""
    
    print("ğŸ”§ Tentative d'installation ONNX optionnelle...")
    
    import subprocess
    import sys
    
    try:
        # Essayer les versions les plus rÃ©centes disponibles
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "onnx", "onnxruntime", "skl2onnx", 
            "--upgrade", "--quiet"
        ])
        print("âœ… ONNX installÃ© avec versions disponibles")
        return True
    except Exception as e:
        print(f"âš ï¸ Installation ONNX Ã©chouÃ©e: {e}")
        print("ğŸ’¡ Continuer avec modÃ¨le sklearn uniquement")
        return False

def install_model_registry():
    """Installation Model Registry uniquement"""
    
    print("ğŸ”§ Installation Model Registry...")
    
    import subprocess
    import sys
    
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "aiohttp-retry", "model-registry==0.2.7a1", "--quiet"
        ])
        print("âœ… Model Registry installÃ©")
        return True
    except Exception as e:
        print(f"âš ï¸ Erreur Model Registry: {e}")
        return False

def evaluate_model():
    """Ã‰value le modÃ¨le sur les donnÃ©es de test"""
    
    print("ğŸ” Chargement du modÃ¨le et des donnÃ©es...")
    
    try:
        # Charger le modÃ¨le
        with open('models/iris_model.pkl', 'rb') as f:
            model = pickle.load(f)
        
        # Charger les donnÃ©es de test
        with open('data/X_test.pkl', 'rb') as f:
            X_test = pickle.load(f)
        with open('data/y_test.pkl', 'rb') as f:
            y_test = pickle.load(f)
        
        # Charger les mÃ©tadonnÃ©es du modÃ¨le
        with open('models/model_metadata.json', 'r') as f:
            model_metadata = json.load(f)
        
        print(f"ğŸ“Š DonnÃ©es de test: {X_test.shape}")
        print(f"ğŸ“Š Labels de test: {y_test.shape}")
        
        # Faire les prÃ©dictions
        print("ğŸ§ª PrÃ©dictions sur les donnÃ©es de test...")
        y_pred = model.predict(X_test)
        
        # Calculer les mÃ©triques
        accuracy = accuracy_score(y_test, y_pred)
        class_report = classification_report(y_test, y_pred, output_dict=True)
        conf_matrix = confusion_matrix(y_test, y_pred)
        
        # Compter les erreurs
        errors = np.sum(y_test != y_pred)
        total_samples = len(y_test)
        
        print(f"ğŸ“ˆ PrÃ©cision du modÃ¨le: {accuracy:.4f}")
        print(f"ğŸ“Š Erreurs de classification: {errors}/{total_samples} Ã©chantillons")
        
        # CrÃ©er le rÃ©pertoire evaluation
        eval_dir = Path("evaluation")
        eval_dir.mkdir(exist_ok=True)
        
        # PrÃ©parer les mÃ©triques complÃ¨tes
        evaluation_metrics = {
            "accuracy": float(accuracy),
            "error_rate": float(errors / total_samples),
            "errors": int(errors),
            "total_samples": int(total_samples),
            "classification_report": class_report,
            "confusion_matrix": conf_matrix.tolist(),
            "model_metadata": model_metadata
        }
        
        # Sauvegarder les mÃ©triques pour Elyra (format pkl attendu)
        with open(eval_dir / "evaluation_metrics.pkl", "wb") as f:
            pickle.dump(evaluation_metrics, f)
        
        # Sauvegarder aussi en JSON pour lisibilitÃ©
        with open(eval_dir / "evaluation_metrics.json", "w") as f:
            json.dump(evaluation_metrics, f, indent=2)
        
        # Sauvegarder accuracy pour KFP
        with open(eval_dir / "accuracy.txt", "w") as f:
            f.write(str(accuracy))
        
        print("ğŸ›ï¸ Logging des mÃ©triques pour KFP...")
        print("âœ… MÃ©triques sauvegardÃ©es au format KFP")
        
        return accuracy, evaluation_metrics, model, X_test
        
    except Exception as e:
        print(f"âŒ Erreur lors de l'Ã©valuation: {e}")
        # CrÃ©er fichiers minimaux pour Elyra
        eval_dir = Path("evaluation")
        eval_dir.mkdir(exist_ok=True)
        
        empty_metrics = {"accuracy": 0.0, "error_message": str(e)}
        
        with open(eval_dir / "evaluation_metrics.pkl", "wb") as f:
            pickle.dump(empty_metrics, f)
        with open(eval_dir / "accuracy.txt", "w") as f:
            f.write("0.0")
            
        return 0.0, {}, None, None

def try_convert_to_onnx(model, X_sample):
    """Tentative de conversion ONNX si possible"""
    
    print("ğŸ”„ Tentative de conversion ONNX...")
    
    try:
        from skl2onnx import convert_sklearn
        from skl2onnx.common.data_types import FloatTensorType
        import onnx
        import onnxruntime as ort
        
        print(f"ğŸ“¦ ONNX disponible - tentative de conversion...")
        
        n_features = X_sample.shape[1]
        initial_type = [('float_input', FloatTensorType([None, n_features]))]
        
        # Conversion simple pour ONNX 1.9 (compatible Triton 23.10)
        onnx_model = convert_sklearn(
            model, 
            initial_types=initial_type,
            options={'zipmap': False},
            target_opset=9
        )
        
        # Sauvegarder
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        onnx_path = models_dir / "iris_model.onnx"
        
        with open(onnx_path, "wb") as f:
            f.write(onnx_model.SerializeToString())
        
        # Test rapide
        session = ort.InferenceSession(str(onnx_path))
        test_input = X_sample[:1].astype(np.float32)
        result = session.run(None, {session.get_inputs()[0].name: test_input})
        
        print(f"âœ… ModÃ¨le ONNX crÃ©Ã© avec succÃ¨s!")
        print(f"ğŸ“Š Taille: {os.path.getsize(onnx_path)} bytes")
        
        return str(onnx_path)
        
    except Exception as e:
        print(f"âŒ Conversion ONNX Ã©chouÃ©e: {e}")
        return None

def get_model_registry_config():
    """Configuration Model Registry"""
    
    model_registry_url = "https://modelregistry-rest.apps.CLUSTER_DOMAIN_PLACEHOLDER"
    token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
    
    try:
        with open(token_path, 'r') as f:
            token = f.read().strip()
        print("ğŸ”“ Connexion via ServiceAccount Kubernetes")
        return model_registry_url, token
    except FileNotFoundError:
        print(f"âŒ Token ServiceAccount non trouvÃ©")
        return None, None

def create_triton_structure_local(onnx_path):
    """CrÃ©e la structure de rÃ©pertoire Triton locale parfaite"""
    
    if not onnx_path or not os.path.exists(onnx_path):
        print("âš ï¸ Pas de modÃ¨le ONNX - structure Triton non crÃ©Ã©e")
        return False
    
    try:
        print("ğŸ”§ CrÃ©ation de la structure Triton locale parfaite...")
        
        # CrÃ©er le rÃ©pertoire iris_model/1
        triton_dir = Path("models/iris_model/1")
        triton_dir.mkdir(parents=True, exist_ok=True)
        
        # Copier le modÃ¨le dans la structure Triton
        triton_model_path = triton_dir / "iris_model.onnx"
        import shutil
        shutil.copy2(onnx_path, triton_model_path)
        
        # CrÃ©er le fichier de configuration Triton DANS le rÃ©pertoire iris_model
        config_path = Path("models/iris_model/config.pbtxt")
        config_content = f"""name: "iris_model"
platform: "onnxruntime_onnx"
max_batch_size: 0
default_model_filename: "iris_model.onnx"
input [
  {{
    name: "float_input"
    data_type: TYPE_FP32
    dims: [ -1, 4 ]
  }}
]
output [
  {{
    name: "output"
    data_type: TYPE_FP32
    dims: [ 1 ]
  }},
  {{
    name: "probabilities"
    data_type: TYPE_FP32
    dims: [ -1, 3 ]
  }}
]
instance_group [
  {{
    count: 1
    kind: KIND_CPU
  }}
]
"""
        config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(config_path, 'w') as f:
            f.write(config_content)
        
        print(f"âœ… Structure Triton parfaite crÃ©Ã©e:")
        print(f"  ğŸ“ {triton_model_path}")
        print(f"  ğŸ“„ {config_path}")
        print(f"  ğŸ“ Structure finale:")
        print(f"    models/iris_model/")
        print(f"    â”œâ”€â”€ config.pbtxt")
        print(f"    â””â”€â”€ 1/")
        print(f"        â””â”€â”€ iris_model.onnx")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur crÃ©ation structure Triton locale: {e}")
        return False

def register_model_in_registry(metrics, onnx_path):
    """Enregistrement dans Model Registry"""
    
    try:
        from model_registry import ModelRegistry
        print("âœ… model_registry importÃ©")
    except ImportError as e:
        print(f"âŒ model_registry non disponible: {e}")
        return False
    
    registry_url, token = get_model_registry_config()
    if not registry_url or not token:
        return False
    
    try:
        print("ğŸ§ª Test de la connexion...")
        registry = ModelRegistry(
            server_address=registry_url,
            author="iris-pipeline-final",
            user_token=token,
            is_secure=False
        )
        
        # Version unique
        import time
        pipeline_id = os.getenv('PIPELINE_RUN_NAME', f'iris-{int(time.time())}')
        unique_version = f"v{int(time.time())}"
        
        # DÃ©terminer format
        if onnx_path and os.path.exists(onnx_path):
            # Structure pour Triton: iris_model/1/iris_model.onnx
            s3_uri = f"s3://mlpipeline/{pipeline_id}/models/iris_model/1/iris_model.onnx"
            model_format = "onnx"
            description = f"ğŸ¯ ModÃ¨le Iris ONNX - Accuracy: {metrics.get('accuracy', 0):.4f} - PrÃªt pour dÃ©ploiement"
        else:
            s3_uri = f"s3://mlpipeline/{pipeline_id}/models/iris_model.pkl"
            model_format = "sklearn"
            description = f"ğŸ“Š ModÃ¨le Iris sklearn - Accuracy: {metrics.get('accuracy', 0):.4f}"
        
        print(f"ğŸ“ Enregistrement: iris-random-forest {unique_version} ({model_format.upper()})")
        
        registered_model = registry.register_model(
            name="iris-random-forest",
            uri=s3_uri,
            version=unique_version,
            model_format_name=model_format,
            model_format_version="1.0",
            description=description,
            metadata={
                "pipeline": "iris-elyra-final",
                "accuracy": float(metrics.get('accuracy', 0)),
                "deployment_ready": onnx_path is not None,
                "pipeline_run": pipeline_id
            }
        )
        
        print(f"âœ… ModÃ¨le enregistrÃ© avec succÃ¨s!")
        print(f"ğŸ“‹ ID: {getattr(registered_model, 'id', 'N/A')}")
        print(f"ğŸ¯ Format: {model_format.upper()}")
        print(f"ğŸ”¢ Version: {unique_version}")
        
        # CrÃ©er la structure Triton dans S3 si c'est un modÃ¨le ONNX
        if onnx_path and os.path.exists(onnx_path):
            print("\nğŸ”§ CrÃ©ation de la structure Triton locale...")
            triton_structure_created = create_triton_structure_local(onnx_path)
            if triton_structure_created:
                print("âœ… Structure Triton prÃªte pour dÃ©ploiement!")
            else:
                print("âš ï¸ Structure Triton non crÃ©Ã©e - dÃ©ploiement manuel requis")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur Model Registry: {e}")
        return False

def create_fallback_files():
    """CrÃ©e les fichiers attendus par Elyra mÃªme si non utilisÃ©s"""
    
    eval_dir = Path("evaluation")
    eval_dir.mkdir(exist_ok=True)
    
    # CrÃ©er registry_info.json mÃªme si l'enregistrement rÃ©ussit
    # (pour Ã©viter l'erreur Elyra)
    fallback_info = {
        "status": "registration_attempted",
        "note": "Voir les logs pour le rÃ©sultat rÃ©el"
    }
    
    with open(eval_dir / "registry_info.json", "w") as f:
        json.dump(fallback_info, f, indent=2)

def main():
    """Fonction principale simplifiÃ©e et robuste"""
    
    print("ğŸš€ Pipeline Iris Final - Robuste et Fonctionnel")
    
    # 1. Installation optionnelle
    onnx_available = try_install_onnx()
    registry_available = install_model_registry()
    
    # 2. Ã‰valuation (prioritÃ© absolue)
    accuracy, metrics, model, X_test = evaluate_model()
    
    if not metrics:
        print("âŒ Impossible de continuer sans mÃ©triques")
        create_fallback_files()
        return
    
    # 3. Conversion ONNX (optionnelle)
    onnx_path = None
    if onnx_available and model is not None and X_test is not None:
        onnx_path = try_convert_to_onnx(model, X_test)
    
    # 4. Enregistrement Model Registry (optionnel)
    registry_success = False
    if registry_available:
        print("\nğŸ›ï¸ Enregistrement Model Registry...")
        registry_success = register_model_in_registry(metrics, onnx_path)
    
    # 5. CrÃ©er les fichiers attendus par Elyra
    create_fallback_files()
    
    # 6. Rapport final
    print(f"\nğŸ’¾ Fichiers crÃ©Ã©s:")
    print(f"  ğŸ“„ evaluation/evaluation_metrics.pkl")
    print(f"  ğŸ“„ evaluation/evaluation_metrics.json") 
    print(f"  ğŸ“„ evaluation/accuracy.txt")
    print(f"  ğŸ“„ evaluation/registry_info.json")
    if onnx_path:
        print(f"  ğŸ“„ models/iris_model.onnx")
    
    print(f"\nğŸ¯ RÃ‰SUMÃ‰ FINAL:")
    print(f"  ğŸ“Š Accuracy: {metrics.get('accuracy', 0):.4f}")
    print(f"  ğŸ¯ ONNX: {'âœ… CrÃ©Ã©' if onnx_path else 'âŒ Non disponible'}")
    print(f"  ğŸ›ï¸ Registry: {'âœ… EnregistrÃ©' if registry_success else 'âŒ Non disponible'}")
    
    if onnx_path and registry_success:
        print(f"\nğŸ‰ SUCCÃˆS COMPLET!")
        print(f"  âœ… ModÃ¨le ONNX prÃªt pour dÃ©ploiement")
    elif registry_success:
        print(f"\nâœ… SUCCÃˆS PARTIEL!")
        print(f"  ğŸ“Š ModÃ¨le sklearn enregistrÃ© - conversion ONNX possible ultÃ©rieurement")
    else:
        print(f"\nâœ… Ã‰VALUATION RÃ‰USSIE!")
        print(f"  ğŸ“Š MÃ©triques sauvegardÃ©es - enregistrement manuel possible")

if __name__ == "__main__":
    main()