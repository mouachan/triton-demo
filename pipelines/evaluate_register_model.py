import os
import json
import pickle
import numpy as np
from pathlib import Path
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

def try_install_onnx():
    """Tentative d'installation ONNX sans forcer"""
    
    print("üîß Tentative d'installation ONNX optionnelle...")
    
    import subprocess
    import sys
    
    try:
        # Essayer les versions les plus r√©centes disponibles
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "onnx", "onnxruntime", "skl2onnx", 
            "--upgrade", "--quiet"
        ])
        print("‚úÖ ONNX install√© avec versions disponibles")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Installation ONNX √©chou√©e: {e}")
        print("üí° Continuer avec mod√®le sklearn uniquement")
        return False

def install_model_registry():
    """Installation Model Registry uniquement"""
    
    print("üîß Installation Model Registry...")
    
    import subprocess
    import sys
    
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "aiohttp-retry", "model-registry==0.2.7a1", "--quiet"
        ])
        print("‚úÖ Model Registry install√©")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur Model Registry: {e}")
        return False

def evaluate_model():
    """√âvalue le mod√®le sur les donn√©es de test"""
    
    print("üîç Chargement du mod√®le et des donn√©es...")
    
    try:
        # Charger le mod√®le
        with open('models/iris_model.pkl', 'rb') as f:
            model = pickle.load(f)
        
        # Charger les donn√©es de test
        with open('data/X_test.pkl', 'rb') as f:
            X_test = pickle.load(f)
        with open('data/y_test.pkl', 'rb') as f:
            y_test = pickle.load(f)
        
        # Charger les m√©tadonn√©es du mod√®le
        with open('models/model_metadata.json', 'r') as f:
            model_metadata = json.load(f)
        
        print(f"üìä Donn√©es de test: {X_test.shape}")
        print(f"üìä Labels de test: {y_test.shape}")
        
        # Faire les pr√©dictions
        print("üß™ Pr√©dictions sur les donn√©es de test...")
        y_pred = model.predict(X_test)
        
        # Calculer les m√©triques
        accuracy = accuracy_score(y_test, y_pred)
        class_report = classification_report(y_test, y_pred, output_dict=True)
        conf_matrix = confusion_matrix(y_test, y_pred)
        
        # Compter les erreurs
        errors = np.sum(y_test != y_pred)
        total_samples = len(y_test)
        
        print(f"üìà Pr√©cision du mod√®le: {accuracy:.4f}")
        print(f"üìä Erreurs de classification: {errors}/{total_samples} √©chantillons")
        
        # Cr√©er le r√©pertoire evaluation
        eval_dir = Path("evaluation")
        eval_dir.mkdir(exist_ok=True)
        
        # Pr√©parer les m√©triques compl√®tes
        evaluation_metrics = {
            "accuracy": float(accuracy),
            "error_rate": float(errors / total_samples),
            "errors": int(errors),
            "total_samples": int(total_samples),
            "classification_report": class_report,
            "confusion_matrix": conf_matrix.tolist(),
            "model_metadata": model_metadata
        }
        
        # Sauvegarder les m√©triques pour Elyra (format pkl attendu)
        with open(eval_dir / "evaluation_metrics.pkl", "wb") as f:
            pickle.dump(evaluation_metrics, f)
        
        # Sauvegarder aussi en JSON pour lisibilit√©
        with open(eval_dir / "evaluation_metrics.json", "w") as f:
            json.dump(evaluation_metrics, f, indent=2)
        
        # Sauvegarder accuracy pour KFP
        with open(eval_dir / "accuracy.txt", "w") as f:
            f.write(str(accuracy))
        
        print("üèõÔ∏è Logging des m√©triques pour KFP...")
        print("‚úÖ M√©triques sauvegard√©es au format KFP")
        
        return accuracy, evaluation_metrics, model, X_test
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'√©valuation: {e}")
        # Cr√©er fichiers minimaux pour Elyra
        eval_dir = Path("evaluation")
        eval_dir.mkdir(exist_ok=True)
        
        empty_metrics = {"accuracy": 0.0, "error_message": str(e)}
        
        with open(eval_dir / "evaluation_metrics.pkl", "wb") as f:
            pickle.dump(empty_metrics, f)
        with open(eval_dir / "accuracy.txt", "w") as f:
            f.write("0.0")
            
        return 0.0, {}, None, None

def try_convert_to_onnx(model, X_sample):
    """Tentative de conversion ONNX si possible"""
    
    print("üîÑ Tentative de conversion ONNX...")
    
    try:
        from skl2onnx import convert_sklearn
        from skl2onnx.common.data_types import FloatTensorType
        import onnx
        import onnxruntime as ort
        
        print(f"üì¶ ONNX disponible - tentative de conversion...")
        
        n_features = X_sample.shape[1]
        initial_type = [('float_input', FloatTensorType([None, n_features]))]
        
        # Conversion simple pour ONNX 1.9 (compatible Triton 23.10)
        onnx_model = convert_sklearn(
            model, 
            initial_types=initial_type,
            options={'zipmap': False},
            target_opset=9
        )
        
        # Sauvegarder
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        onnx_path = models_dir / "iris_model.onnx"
        
        with open(onnx_path, "wb") as f:
            f.write(onnx_model.SerializeToString())
        
        # Test rapide
        session = ort.InferenceSession(str(onnx_path))
        test_input = X_sample[:1].astype(np.float32)
        result = session.run(None, {session.get_inputs()[0].name: test_input})
        
        print(f"‚úÖ Mod√®le ONNX cr√©√© avec succ√®s!")
        print(f"üìä Taille: {os.path.getsize(onnx_path)} bytes")
        
        return str(onnx_path)
        
    except Exception as e:
        print(f"‚ùå Conversion ONNX √©chou√©e: {e}")
        return None

def get_model_registry_config():
    """Configuration Model Registry"""
    
    model_registry_url = "https://modelregistry-rest.apps.CLUSTER_DOMAIN_PLACEHOLDER"
    token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
    
    try:
        with open(token_path, 'r') as f:
            token = f.read().strip()
        print("üîì Connexion via ServiceAccount Kubernetes")
        return model_registry_url, token
    except FileNotFoundError:
        print(f"‚ùå Token ServiceAccount non trouv√©")
        return None, None

def create_triton_structure_local(onnx_path):
    """Cr√©e la structure de r√©pertoire Triton locale parfaite"""
    
    if not onnx_path or not os.path.exists(onnx_path):
        print("‚ö†Ô∏è Pas de mod√®le ONNX - structure Triton non cr√©√©e")
        return False
    
    try:
        print("üîß Cr√©ation de la structure Triton locale parfaite...")
        
        # Cr√©er le r√©pertoire iris_model/1
        triton_dir = Path("models/iris_model/1")
        triton_dir.mkdir(parents=True, exist_ok=True)
        
        # Copier le mod√®le dans la structure Triton
        triton_model_path = triton_dir / "iris_model.onnx"
        import shutil
        shutil.copy2(onnx_path, triton_model_path)
        
        # Cr√©er le fichier de configuration Triton DANS le r√©pertoire iris_model
        config_path = Path("models/iris_model/config.pbtxt")
        config_content = f"""name: "iris_model"
platform: "onnxruntime_onnx"
max_batch_size: 0
default_model_filename: "iris_model.onnx"
input [
  {{
    name: "float_input"
    data_type: TYPE_FP32
    dims: [ -1, 4 ]
  }}
]
output [
  {{
    name: "output"
    data_type: TYPE_FP32
    dims: [ 1 ]
  }},
  {{
    name: "probabilities"
    data_type: TYPE_FP32
    dims: [ -1, 3 ]
  }}
]
instance_group [
  {{
    count: 1
    kind: KIND_CPU
  }}
]
"""
        config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(config_path, 'w') as f:
            f.write(config_content)
        
        print(f"‚úÖ Structure Triton parfaite cr√©√©e:")
        print(f"  üìÅ {triton_model_path}")
        print(f"  üìÑ {config_path}")
        print(f"  üìÅ Structure finale:")
        print(f"    models/iris_model/")
        print(f"    ‚îú‚îÄ‚îÄ config.pbtxt")
        print(f"    ‚îî‚îÄ‚îÄ 1/")
        print(f"        ‚îî‚îÄ‚îÄ iris_model.onnx")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation structure Triton locale: {e}")
        return False

def register_model_in_registry(metrics, onnx_path):
    """Enregistrement dans Model Registry"""
    
    try:
        from model_registry import ModelRegistry
        print("‚úÖ model_registry import√©")
    except ImportError as e:
        print(f"‚ùå model_registry non disponible: {e}")
        return False
    
    registry_url, token = get_model_registry_config()
    if not registry_url or not token:
        return False
    
    try:
        print("üß™ Test de la connexion...")
        registry = ModelRegistry(
            server_address=registry_url,
            author="iris-pipeline-final",
            user_token=token,
            is_secure=False
        )
        
        # Version unique
        import time
        pipeline_id = os.getenv('PIPELINE_RUN_NAME', f'iris-{int(time.time())}')
        unique_version = f"v{int(time.time())}"
        
        # D√©terminer format
        if onnx_path and os.path.exists(onnx_path):
            # Structure pour Triton: iris_model/1/iris_model.onnx
            s3_uri = f"s3://mlpipeline/{pipeline_id}/models/iris_model/1/iris_model.onnx"
            model_format = "onnx"
            description = f"üéØ Mod√®le Iris ONNX - Accuracy: {metrics.get('accuracy', 0):.4f} - Pr√™t pour d√©ploiement"
        else:
            s3_uri = f"s3://mlpipeline/{pipeline_id}/models/iris_model.pkl"
            model_format = "sklearn"
            description = f"üìä Mod√®le Iris sklearn - Accuracy: {metrics.get('accuracy', 0):.4f}"
        
        print(f"üìù Enregistrement: iris-random-forest {unique_version} ({model_format.upper()})")
        
        registered_model = registry.register_model(
            name="iris-random-forest",
            uri=s3_uri,
            version=unique_version,
            model_format_name=model_format,
            model_format_version="1.0",
            description=description,
            metadata={
                "pipeline": "iris-elyra-final",
                "accuracy": float(metrics.get('accuracy', 0)),
                "deployment_ready": onnx_path is not None,
                "pipeline_run": pipeline_id
            }
        )
        
        print(f"‚úÖ Mod√®le enregistr√© avec succ√®s!")
        print(f"üìã ID: {getattr(registered_model, 'id', 'N/A')}")
        print(f"üéØ Format: {model_format.upper()}")
        print(f"üî¢ Version: {unique_version}")
        
        # Cr√©er la structure Triton dans S3 si c'est un mod√®le ONNX
        if onnx_path and os.path.exists(onnx_path):
            print("\nüîß Cr√©ation de la structure Triton locale...")
            triton_structure_created = create_triton_structure_local(onnx_path)
            if triton_structure_created:
                print("‚úÖ Structure Triton pr√™te pour d√©ploiement!")
            else:
                print("‚ö†Ô∏è Structure Triton non cr√©√©e - d√©ploiement manuel requis")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur Model Registry: {e}")
        return False

def create_fallback_files():
    """Cr√©e les fichiers attendus par Elyra m√™me si non utilis√©s"""
    
    eval_dir = Path("evaluation")
    eval_dir.mkdir(exist_ok=True)
    
    # Cr√©er registry_info.json m√™me si l'enregistrement r√©ussit
    # (pour √©viter l'erreur Elyra)
    fallback_info = {
        "status": "registration_attempted",
        "note": "Voir les logs pour le r√©sultat r√©el"
    }
    
    with open(eval_dir / "registry_info.json", "w") as f:
        json.dump(fallback_info, f, indent=2)

def main():
    """Fonction principale simplifi√©e et robuste"""
    
    print("üöÄ Pipeline Iris Final - Robuste et Fonctionnel")
    
    # 1. Installation optionnelle
    onnx_available = try_install_onnx()
    registry_available = install_model_registry()
    
    # 2. √âvaluation (priorit√© absolue)
    accuracy, metrics, model, X_test = evaluate_model()
    
    if not metrics:
        print("‚ùå Impossible de continuer sans m√©triques")
        create_fallback_files()
        return
    
    # 3. Conversion ONNX (optionnelle)
    onnx_path = None
    if onnx_available and model is not None and X_test is not None:
        onnx_path = try_convert_to_onnx(model, X_test)
    
    # 4. Enregistrement Model Registry (optionnel)
    registry_success = False
    if registry_available:
        print("\nüèõÔ∏è Enregistrement Model Registry...")
        registry_success = register_model_in_registry(metrics, onnx_path)
    
    # 5. Cr√©er les fichiers attendus par Elyra
    create_fallback_files()
    
    # 6. Rapport final
    print(f"\nüíæ Fichiers cr√©√©s:")
    print(f"  üìÑ evaluation/evaluation_metrics.pkl")
    print(f"  üìÑ evaluation/evaluation_metrics.json") 
    print(f"  üìÑ evaluation/accuracy.txt")
    print(f"  üìÑ evaluation/registry_info.json")
    if onnx_path:
        print(f"  üìÑ models/iris_model.onnx")
    
    print(f"\nüéØ R√âSUM√â FINAL:")
    print(f"  üìä Accuracy: {metrics.get('accuracy', 0):.4f}")
    print(f"  üéØ ONNX: {'‚úÖ Cr√©√©' if onnx_path else '‚ùå Non disponible'}")
    print(f"  üèõÔ∏è Registry: {'‚úÖ Enregistr√©' if registry_success else '‚ùå Non disponible'}")
    
    if onnx_path and registry_success:
        print(f"\nüéâ SUCC√àS COMPLET!")
        print(f"  ‚úÖ Mod√®le ONNX pr√™t pour d√©ploiement")
    elif registry_success:
        print(f"\n‚úÖ SUCC√àS PARTIEL!")
        print(f"  üìä Mod√®le sklearn enregistr√© - conversion ONNX possible ult√©rieurement")
    else:
        print(f"\n‚úÖ √âVALUATION R√âUSSIE!")
        print(f"  üìä M√©triques sauvegard√©es - enregistrement manuel possible")

if __name__ == "__main__":
    main()