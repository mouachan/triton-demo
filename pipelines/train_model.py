import os
import pickle
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import argparse

def train_model_with_onnx(data_path="data", output_path="models"):
    print("ğŸ¤– EntraÃ®nement du modÃ¨le Random Forest + Export ONNX")
    print("=" * 60)
    
    # CrÃ©er le dossier de sortie pour les modÃ¨les
    os.makedirs(output_path, exist_ok=True)
    
    print("ğŸ“‚ Chargement des donnÃ©es d'entraÃ®nement...")
    
    # Charger les donnÃ©es d'entraÃ®nement et de test
    with open(os.path.join(data_path, 'X_train.pkl'), 'rb') as f:
        X_train = pickle.load(f)
    
    with open(os.path.join(data_path, 'y_train.pkl'), 'rb') as f:
        y_train = pickle.load(f)
    
    with open(os.path.join(data_path, 'X_test.pkl'), 'rb') as f:
        X_test = pickle.load(f)
    
    with open(os.path.join(data_path, 'y_test.pkl'), 'rb') as f:
        y_test = pickle.load(f)
    
    # Charger les mÃ©tadonnÃ©es si disponibles, sinon utiliser les valeurs par dÃ©faut
    metadata = {}
    metadata_file = os.path.join(data_path, 'metadata.pkl')
    if os.path.exists(metadata_file):
        with open(metadata_file, 'rb') as f:
            metadata = pickle.load(f)
        feature_names = metadata['feature_names']
        target_names = metadata['target_names']
    else:
        # Valeurs par dÃ©faut pour le dataset Iris si mÃ©tadonnÃ©es non disponibles
        feature_names = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
        target_names = ['setosa', 'versicolor', 'virginica']
        print("âš ï¸  MÃ©tadonnÃ©es non trouvÃ©es - utilisation des valeurs par dÃ©faut Iris")
    
    print(f"ğŸ“Š DonnÃ©es chargÃ©es: {X_train.shape[0]} Ã©chantillons d'entraÃ®nement")
    print(f"ğŸ“Š Features: {feature_names}")
    print(f"ğŸ¯ Classes: {target_names}")
    
    # Configuration du modÃ¨le
    n_estimators = int(os.getenv('N_ESTIMATORS', 100))
    max_depth = int(os.getenv('MAX_DEPTH', 10))
    random_state = int(os.getenv('RANDOM_STATE', 42))
    
    print(f"ğŸŒ³ Configuration: {n_estimators} arbres, profondeur max: {max_depth}")
    
    # CrÃ©er et entraÃ®ner le modÃ¨le
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state,
        n_jobs=-1  # Utiliser tous les CPU disponibles
    )
    
    print("ğŸ”„ EntraÃ®nement en cours...")
    model.fit(X_train, y_train)
    
    # Ã‰valuation du modÃ¨le
    print("ğŸ“ˆ Ã‰valuation du modÃ¨le...")
    train_accuracy = model.score(X_train, y_train)
    test_accuracy = model.score(X_test, y_test)
    
    # PrÃ©dictions pour le rapport dÃ©taillÃ©
    y_pred = model.predict(X_test)
    
    print(f"âœ… Accuracy d'entraÃ®nement: {train_accuracy:.4f}")
    print(f"âœ… Accuracy de test: {test_accuracy:.4f}")
    
    # Rapport de classification
    print("\nğŸ“Š Rapport de classification:")
    print(classification_report(y_test, y_pred, target_names=target_names))
    
    # Importance des features
    feature_importance = dict(zip(feature_names, model.feature_importances_))
    print("\nğŸ” Importance des features:")
    for feature, importance in sorted(feature_importance.items(), key=lambda x: x[1], reverse=True):
        print(f"  {feature}: {importance:.4f}")
    
    # 1. Sauvegarder le modÃ¨le scikit-learn (format pickle)
    model_pkl_path = os.path.join(output_path, 'iris_model.pkl')
    with open(model_pkl_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"ğŸ’¾ ModÃ¨le scikit-learn sauvegardÃ©: {model_pkl_path}")
    
    # 2. Exporter vers ONNX
    print("\nğŸ”„ Export vers ONNX...")
    try:
        from skl2onnx import convert_sklearn
        from skl2onnx.common.data_types import FloatTensorType
        
        # DÃ©finir le type d'entrÃ©e ONNX
        initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]
        
        # Convertir le modÃ¨le vers ONNX
        onnx_model = convert_sklearn(
            model, 
            initial_types=initial_type,
            target_opset=11,  # Version ONNX compatible
            options={id(model): {'zipmap': False}}  # Sortie simplifiÃ©e
        )
        
        # Sauvegarder le modÃ¨le ONNX
        onnx_path = os.path.join(output_path, 'iris_model.onnx')
        with open(onnx_path, 'wb') as f:
            f.write(onnx_model.SerializeToString())
        
        print(f"âœ… ModÃ¨le ONNX exportÃ©: {onnx_path}")
        
        # VÃ©rifier le modÃ¨le ONNX
        try:
            import onnx
            onnx_model_check = onnx.load(onnx_path)
            onnx.checker.check_model(onnx_model_check)
            print("âœ… ModÃ¨le ONNX validÃ© avec succÃ¨s")
            
            # Tester l'infÃ©rence ONNX
            try:
                import onnxruntime as ort
                
                # CrÃ©er une session d'infÃ©rence
                ort_session = ort.InferenceSession(onnx_path)
                
                # Test avec quelques Ã©chantillons
                X_test_sample = X_test[:3].astype(np.float32)
                
                # PrÃ©diction ONNX
                ort_inputs = {ort_session.get_inputs()[0].name: X_test_sample}
                ort_outputs = ort_session.run(None, ort_inputs)
                
                # PrÃ©diction scikit-learn pour comparaison
                sklearn_pred = model.predict(X_test_sample)
                onnx_pred = ort_outputs[0]
                
                print(f"ğŸ” Test d'infÃ©rence:")
                print(f"  Scikit-learn: {sklearn_pred}")
                print(f"  ONNX: {onnx_pred}")
                
                # VÃ©rifier la cohÃ©rence
                if np.array_equal(sklearn_pred, onnx_pred):
                    print("âœ… ModÃ¨les scikit-learn et ONNX cohÃ©rents")
                else:
                    print("âš ï¸  DiffÃ©rence entre modÃ¨les scikit-learn et ONNX")
                    
            except ImportError:
                print("âš ï¸  ONNXRuntime non disponible - test d'infÃ©rence ignorÃ©")
                
        except ImportError:
            print("âš ï¸  Package onnx non disponible - validation ignorÃ©e")
            
    except ImportError:
        print("âš ï¸  skl2onnx non disponible - export ONNX ignorÃ©")
        print("ğŸ’¡ Pour activer ONNX: pip install skl2onnx onnx onnxruntime")
        onnx_path = None
    
    # 3. Sauvegarder les mÃ©tadonnÃ©es du modÃ¨le
    model_metadata = {
        "model_type": "RandomForestClassifier",
        "n_estimators": n_estimators,
        "max_depth": max_depth,
        "train_accuracy": float(train_accuracy),
        "test_accuracy": float(test_accuracy),
        "feature_names": feature_names,
        "target_names": target_names,
        "feature_importance": feature_importance,
        "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
        "classification_report": classification_report(y_test, y_pred, target_names=target_names, output_dict=True),
        "model_formats": {
            "pickle": "iris_model.pkl",
            "onnx": "iris_model.onnx" if onnx_path else None
        },
        "input_schema": {
            "type": "float32",
            "shape": [None, len(feature_names)],
            "features": feature_names
        },
        "output_schema": {
            "type": "int64",
            "classes": target_names
        }
    }
    
    model_metadata_path = os.path.join(output_path, 'model_metadata.pkl')
    with open(model_metadata_path, 'wb') as f:
        pickle.dump(model_metadata, f)
    
    # Sauvegarder Ã©galement en JSON pour faciliter la lecture
    import json
    model_metadata_json_path = os.path.join(output_path, 'model_metadata.json')
    with open(model_metadata_json_path, 'w') as f:
        json.dump(model_metadata, f, indent=2)
    
    print(f"\nğŸ’¾ MÃ©tadonnÃ©es sauvegardÃ©es:")
    print(f"  ğŸ“„ {model_metadata_path}")
    print(f"  ğŸ“„ {model_metadata_json_path}")
    
    print("\nğŸ‰ EntraÃ®nement et export terminÃ©s avec succÃ¨s!")
    
    # RÃ©sumÃ© des fichiers crÃ©Ã©s
    print("\nğŸ“ Fichiers crÃ©Ã©s:")
    print(f"  ğŸ¤– ModÃ¨le scikit-learn: iris_model.pkl")
    if onnx_path:
        print(f"  ğŸ”„ ModÃ¨le ONNX: iris_model.onnx")
    print(f"  ğŸ“‹ MÃ©tadonnÃ©es: model_metadata.pkl/.json")
    
    # Recommandation pour Model Registry
    print("\nğŸ›ï¸ Pour Model Registry OpenShift AI:")
    if onnx_path:
        print("âœ… Utilisez le fichier ONNX (format standard MLOps)")
        print("ğŸ“‚ Fichier principal: iris_model.onnx")
    else:
        print("ğŸ“‚ Fichier principal: iris_model.pkl")
    print("ğŸ“‹ MÃ©tadonnÃ©es: model_metadata.json")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="EntraÃ®nement du modÃ¨le Iris avec export ONNX")
    parser.add_argument("--data_path", type=str, default="data",
                       help="Chemin vers les donnÃ©es preprocessÃ©es")
    parser.add_argument("--output_path", type=str, default="models",
                       help="Chemin de sortie pour le modÃ¨le entraÃ®nÃ©")
    
    args = parser.parse_args()
    train_model_with_onnx(args.data_path, args.output_path)